# PyTorch Lightningç‰ˆæœ¬ä½¿ç”¨è¯´æ˜

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# GPUç‰ˆæœ¬ (æ¨èï¼Œéœ€è¦NVIDIAæ˜¾å¡ + CUDA)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install pytorch-lightning pandas numpy scikit-learn matplotlib tqdm

# æˆ–è€…CPUç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install pytorch-lightning pandas numpy scikit-learn matplotlib tqdm
```

### 2. è¿è¡Œè®­ç»ƒ

```bash
python train24_lstm_pytorch.py
```

## ğŸ“Š è®­ç»ƒè¾“å‡ºç¤ºä¾‹

```
============================================================
GPUé…ç½®
============================================================
âœ“ æ£€æµ‹åˆ°GPU: NVIDIA GeForce RTX 3080
âœ“ CUDAç‰ˆæœ¬: 11.8
âœ“ GPUæ•°é‡: 1
============================================================

è®­ç»ƒé…ç½®
============================================================
âœ“ batch_size: 128
âœ“ è®­ç»ƒbatches: 712
âœ“ éªŒè¯batches: 177
============================================================

å¼€å§‹è®­ç»ƒ...
æ¯ä¸ªepochåŒ…å«:
  1. è®­ç»ƒé˜¶æ®µ - æœ‰è¿›åº¦æ¡æ˜¾ç¤º train_loss å’Œ train_mae
  2. éªŒè¯é˜¶æ®µ - æœ‰è¿›åº¦æ¡æ˜¾ç¤º val_loss å’Œ val_mae

Epoch 1/100:
Training:   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 712/712 [03:45<00:00, 3.16batch/s, train_loss=0.523, train_mae=0.398]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:28<00:00, 6.21batch/s, val_loss=0.567, val_mae=0.421, val_acc_=85.32, val_acc_mae=87.45]

Epoch 2/100:
Training:   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 712/712 [03:42<00:00, 3.20batch/s, train_loss=0.498, train_mae=0.385]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 177/177 [00:27<00:00, 6.35batch/s, val_loss=0.543, val_mae=0.408, val_acc_=86.12, val_acc_mae=88.23]
```

## âœ¨ ä¸»è¦ç‰¹æ€§

### 1. è‡ªåŠ¨GPUåŠ é€Ÿ
- è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨GPU
- å¦‚æœæ²¡æœ‰GPUï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°CPU

### 2. åŒè¿›åº¦æ¡
- **è®­ç»ƒè¿›åº¦æ¡**: æ˜¾ç¤º train_loss å’Œ train_mae
- **éªŒè¯è¿›åº¦æ¡**: æ˜¾ç¤º val_lossã€val_maeã€val_acc_ã€val_acc_mae

### 3. æ—©åœæœºåˆ¶
- éªŒè¯lossè¿ç»­10ä¸ªepochä¸ä¸‹é™è‡ªåŠ¨åœæ­¢
- è‡ªåŠ¨æ¢å¤æœ€ä½³æƒé‡

### 4. å­¦ä¹ ç‡è¡°å‡
- éªŒè¯lossè¿ç»­5ä¸ªepochä¸ä¸‹é™ï¼Œå­¦ä¹ ç‡å‡åŠ
- æœ€å°å­¦ä¹ ç‡: 0.00001

### 5. è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- ä¿å­˜è·¯å¾„: `./checkpoints/`
- æ–‡ä»¶å: `lstm-{epoch:02d}-{val_loss:.4f}.ckpt`

### 6. ACCæŒ‡æ ‡
- **ACC_**: åŸºäºRMSEçš„ç›¸å¯¹è¯¯å·®
- **ACC_MAE**: åŸºäºMAEçš„ç›¸å¯¹è¯¯å·®
- è‡ªåŠ¨å¿½ç•¥çœŸå®å€¼ä¸º0çš„æ ·æœ¬

## ğŸ“ è¾“å‡ºæ–‡ä»¶

```
checkpoints/
  â””â”€â”€ lstm-15-0.4523.ckpt          # æœ€ä½³æ¨¡å‹
scalers_pytorch.pkl                 # æ•°æ®å½’ä¸€åŒ–å™¨
lightning_logs/                     # TensorBoardæ—¥å¿—
  â””â”€â”€ version_0/
      â”œâ”€â”€ checkpoints/
      â”œâ”€â”€ events.out.tfevents...
      â””â”€â”€ hparams.yaml
```

## ğŸ” æŸ¥çœ‹è®­ç»ƒæ—¥å¿—ï¼ˆTensorBoardï¼‰

```bash
tensorboard --logdir=lightning_logs
```

ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€: http://localhost:6006

## âš™ï¸ ä¿®æ”¹è®­ç»ƒå‚æ•°

### ä¿®æ”¹batch_size

```python
# train24_lstm_pytorch.py ç¬¬308è¡Œ
batch_size = 128  # æ”¹æˆä½ æƒ³è¦çš„å€¼
```

### ä¿®æ”¹epochs

```python
# train24_lstm_pytorch.py ç¬¬392è¡Œ
trainer = pl.Trainer(
    max_epochs=100,  # æ”¹æˆä½ æƒ³è¦çš„å€¼
    ...
)
```

### ä¿®æ”¹æ—©åœpatience

```python
# train24_lstm_pytorch.py ç¬¬370è¡Œ
EarlyStopping(
    monitor='val_loss',
    patience=10,  # æ”¹æˆä½ æƒ³è¦çš„å€¼
    ...
)
```

## ğŸ†š ä¸Kerasç‰ˆæœ¬å¯¹æ¯”

| ç‰¹æ€§ | Kerasç‰ˆæœ¬ | PyTorch Lightningç‰ˆæœ¬ |
|------|----------|---------------------|
| æ¡†æ¶ | TensorFlow/Keras | PyTorch Lightning |
| GPUæ”¯æŒ | âœ… | âœ… |
| è¿›åº¦æ¡ | tqdm | å†…ç½® + tqdm |
| æ—©åœ | âœ… | âœ… |
| å­¦ä¹ ç‡è¡°å‡ | âœ… | âœ… |
| æ¨¡å‹ç»“æ„ | ç›¸åŒ | ç›¸åŒ |
| ä»£ç è¡Œæ•° | ~350è¡Œ | ~450è¡Œ |
| çµæ´»æ€§ | ä¸­ç­‰ | é«˜ |
| TensorBoard | éœ€è¦é…ç½® | è‡ªåŠ¨ç”Ÿæˆ |

## ğŸ’¡ ä½¿ç”¨å»ºè®®

1. **é¦–æ¬¡ä½¿ç”¨**: å…ˆç”¨é»˜è®¤å‚æ•°è¿è¡Œï¼Œçœ‹çœ‹æ•ˆæœ
2. **è°ƒå‚**: æ ¹æ®val_lossæ›²çº¿è°ƒæ•´å­¦ä¹ ç‡ã€batch_sizeç­‰
3. **GPUæ˜¾å­˜ä¸å¤Ÿ**: å‡å°batch_sizeï¼ˆå¦‚64ï¼‰
4. **è®­ç»ƒå¤ªæ…¢**: å¢å¤§batch_sizeï¼ˆå¦‚256ï¼‰
5. **æƒ³è¦æ›´å¤šæ§åˆ¶**: PyTorch Lightningæä¾›äº†ä¸°å¯Œçš„hookså’Œcallbacks

## ğŸ› å¸¸è§é—®é¢˜

### Q: å¦‚ä½•åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Ÿ

```python
from train24_lstm_pytorch import LSTMPowerPredictor

# ä»checkpointåŠ è½½
model = LSTMPowerPredictor.load_from_checkpoint('checkpoints/lstm-15-0.4523.ckpt')

# é¢„æµ‹
model.eval()
with torch.no_grad():
    predictions = model(X_test)
```

### Q: å¦‚ä½•åœ¨å¤šGPUä¸Šè®­ç»ƒï¼Ÿ

```python
trainer = pl.Trainer(
    max_epochs=100,
    accelerator='gpu',
    devices=2,  # ä½¿ç”¨2ä¸ªGPU
    strategy='ddp'  # åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ
)
```

### Q: è®­ç»ƒä¸­æ–­äº†æ€ä¹ˆæ¢å¤ï¼Ÿ

```python
# ä»æœ€åä¸€ä¸ªcheckpointæ¢å¤
trainer.fit(model, train_loader, val_loader, ckpt_path='last')
```

## ğŸ“š æ›´å¤šèµ„æº

- [PyTorch Lightningæ–‡æ¡£](https://lightning.ai/docs/pytorch/stable/)
- [PyTorchæ–‡æ¡£](https://pytorch.org/docs/stable/index.html)
- [TensorBoardæ•™ç¨‹](https://www.tensorflow.org/tensorboard)
